# AI Chat with MCP Weather Integration

A FastAPI backend that integrates OpenAI GPT-4 with Model Context Protocol (MCP) tools for weather information.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚    â”‚  FastAPI Backendâ”‚    â”‚   MCP Weather   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚     Tool        â”‚
â”‚  - Chat UI      â”‚â—„â”€â”€â–ºâ”‚  - OpenAI API   â”‚â—„â”€â”€â–ºâ”‚  - Weather API  â”‚
â”‚  - Material UI  â”‚    â”‚  - MCP Client   â”‚    â”‚  - JSON-RPC     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

- ğŸ¤– **AI-Powered Chat**: OpenAI GPT-4 with function calling
- ğŸŒ¤ï¸ **Weather Integration**: Real-time weather data via MCP
- ğŸ”§ **MCP Protocol**: Standard Model Context Protocol implementation
- ğŸš€ **FastAPI Backend**: High-performance async API
- ğŸ¨ **React Frontend**: Modern chat interface with Material UI

## Project Structure

```
weather-python/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py              # FastAPI endpoints
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”œâ”€â”€ exceptions.py       # Custom exceptions
â”‚   â”œâ”€â”€ mcp_client.py       # MCP protocol client
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ openai_service.py  # OpenAI integration service
â”œâ”€â”€ mcp_tools/
â”‚   â””â”€â”€ weather.py          # MCP weather tool definition
â”œâ”€â”€ main.py                 # MCP server entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## Setup

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Environment Variables

Create a `.env` file:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Run the Backend

```bash
uvicorn app.api:app --host 0.0.0.0 --port 8005 --reload
```

### 4. Run the Frontend

```bash
cd ../ai-chat-frontend
npm start
```

## API Endpoints

- `POST /api/ask` - Process questions with AI and MCP tools
- `GET /health` - Health check endpoint

## MCP Integration

The backend implements the Model Context Protocol (MCP) over stdio:

1. **Handshake**: Initialize MCP connection
2. **Tool Discovery**: Register available tools
3. **Tool Execution**: Call weather tool when needed
4. **Response Processing**: Handle MCP responses

## Development

### Adding New MCP Tools

1. Create tool definition in `mcp_tools/`
2. Update `config.py` with tool configuration
3. Add tool schema to `openai_service.py`
4. Update API logic in `api.py`

### Error Handling

The application uses custom exceptions for better error handling:

- `MCPError` - Base MCP exceptions
- `OpenAIError` - OpenAI API errors
- `WeatherAPIError` - Weather service errors

## Configuration

All configuration is centralized in `app/config.py`:

- OpenAI settings
- Server configuration
- MCP protocol settings
- CORS configuration

## Future Enhancements

- [ ] Add more MCP tools (calendar, email, etc.)
- [ ] Implement conversation history
- [ ] Add user authentication
- [ ] Support for multiple AI models
- [ ] Real-time chat with WebSockets
